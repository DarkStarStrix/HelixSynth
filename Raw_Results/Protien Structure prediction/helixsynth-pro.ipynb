{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10854515,"sourceType":"datasetVersion","datasetId":6742009}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport gc\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom scipy.stats import spearmanr\nimport time\nimport json\nfrom datetime import datetime\nimport warnings\nimport math\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:03.945622Z","iopub.execute_input":"2025-02-27T21:43:03.945969Z","iopub.status.idle":"2025-02-27T21:43:03.951456Z","shell.execute_reply.started":"2025-02-27T21:43:03.945934Z","shell.execute_reply":"2025-02-27T21:43:03.950526Z"}},"outputs":[],"execution_count":258},{"cell_type":"code","source":"# Cell 2: Utility Functions\ndef setup_gpu():\n    \"\"\"Set up GPU for training if available\"\"\"\n    if torch.cuda.is_available():\n        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n        device = torch.device(\"cuda\")\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cudnn.deterministic = False\n        torch.cuda.empty_cache()\n        if torch.cuda.device_count() > 1:\n            print(f\"Using {torch.cuda.device_count()} GPUs\")\n    else:\n        device = torch.device(\"cpu\")\n        print(\"No GPU available, using CPU\")\n    return device\n\ndef set_seed(seed=42):\n    \"\"\"Set seeds for reproducibility\"\"\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    return seed\n\ndef create_synthetic_dataset(output_dir, num_samples=1000, input_dim=400, structured=True):\n    \"\"\"\n    Create synthetic protein structure data\n    \n    Args:\n        output_dir: Directory to save the data\n        num_samples: Number of samples to generate\n        input_dim: Dimension of each sample\n        structured: Whether to add structure to the random data\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for i in range(num_samples):\n        if structured:\n            # Create more structured data with patterns\n            base = np.random.rand(input_dim // 4).astype(np.float32)\n            # Add some repeating patterns to simulate protein motifs\n            structure = np.tile(base, 4) + 0.05 * np.random.randn(input_dim).astype(np.float32)\n            # Add some correlation between features\n            structure += np.sin(np.linspace(0, 8 * np.pi, input_dim)) * 0.1\n            # Normalize to 0-1 range\n            structure = (structure - structure.min()) / (structure.max() - structure.min())\n        else:\n            # Simple random data\n            structure = np.random.rand(input_dim).astype(np.float32)\n        \n        np.save(os.path.join(output_dir, f\"protein_{i}.npy\"), structure)\n    \n    print(f\"Created {num_samples} synthetic protein structures in {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:03.965163Z","iopub.execute_input":"2025-02-27T21:43:03.965394Z","iopub.status.idle":"2025-02-27T21:43:03.977572Z","shell.execute_reply.started":"2025-02-27T21:43:03.965372Z","shell.execute_reply":"2025-02-27T21:43:03.976856Z"}},"outputs":[],"execution_count":259},{"cell_type":"code","source":"# Cell 3: Dataset and DataLoader Classes\nclass ProteinStructureDataset(Dataset):\n    def __init__(self, data_path=None, data=None, transform=None):\n        \"\"\"\n        Initialize dataset either from a directory of files or from provided data\n        \n        Args:\n            data_path: Path to directory with protein structure data files\n            data: Directly provided data (numpy array)\n            transform: Optional transforms to apply\n        \"\"\"\n        self.transform = transform\n        \n        if data is not None:\n            self.data = data\n            self.from_memory = True\n        else:\n            self.data_path = data_path\n            self.data_files = self._get_data_files()\n            self.from_memory = False\n            \n    def _get_data_files(self):\n        \"\"\"Get all data files from the directory\"\"\"\n        files = [os.path.join(self.data_path, f) for f in os.listdir(self.data_path)\n                if f.endswith('.npy') or f.endswith('.npz')]\n        return files\n    \n    def __len__(self):\n        \"\"\"Return the size of the dataset\"\"\"\n        if self.from_memory:\n            return len(self.data)\n        return len(self.data_files)\n    \n    def __getitem__(self, idx):\n        \"\"\"Get a specific data item\"\"\"\n        if self.from_memory:\n            structure = self.data[idx]\n        else:\n            structure = np.load(self.data_files[idx])\n            \n        if self.transform:\n            structure = self.transform(structure)\n            \n        return torch.tensor(structure, dtype=torch.float32)\n\ndef create_data_loaders(data_path=None, data=None, batch_size=128, \n                        num_workers=4, pin_memory=True, train_ratio=0.7, \n                        val_ratio=0.15, test_ratio=0.15, shuffle=True):\n    \"\"\"\n    Create train, validation, and test data loaders\n    \n    Args:\n        data_path: Path to data directory\n        data: Directly provided data array\n        batch_size: Batch size for the loaders\n        num_workers: Number of workers for loading\n        pin_memory: Whether to pin memory\n        train_ratio, val_ratio, test_ratio: Dataset split ratios\n        shuffle: Whether to shuffle the data\n    \"\"\"\n    if data is not None:\n        # Create a dataset from provided data\n        dataset = ProteinStructureDataset(data=data)\n        \n        # Split data \n        total_size = len(dataset)\n        train_size = int(train_ratio * total_size)\n        val_size = int(val_ratio * total_size)\n        test_size = total_size - train_size - val_size\n        \n        train_data, val_data, test_data = torch.utils.data.random_split(\n            dataset, [train_size, val_size, test_size]\n        )\n    else:\n        # Load from path\n        train_data = ProteinStructureDataset(os.path.join(data_path, 'train'))\n        val_data = ProteinStructureDataset(os.path.join(data_path, 'val'))\n        test_data = ProteinStructureDataset(os.path.join(data_path, 'test'))\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_data,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        persistent_workers=(num_workers > 0),\n        prefetch_factor=2 if num_workers > 0 else None,\n    )\n    \n    val_loader = DataLoader(\n        val_data,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        persistent_workers=(num_workers > 0),\n        prefetch_factor=2 if num_workers > 0 else None,\n    )\n    \n    test_loader = DataLoader(\n        test_data,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        persistent_workers=(num_workers > 0),\n        prefetch_factor=2 if num_workers > 0 else None,\n    )\n    \n    return train_loader, val_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:03.980445Z","iopub.execute_input":"2025-02-27T21:43:03.980641Z","iopub.status.idle":"2025-02-27T21:43:04.004500Z","shell.execute_reply.started":"2025-02-27T21:43:03.980623Z","shell.execute_reply":"2025-02-27T21:43:04.003874Z"}},"outputs":[],"execution_count":260},{"cell_type":"code","source":"# Cell 4: VAE Model\nclass ProteinVAE(nn.Module):\n    def __init__(self, input_dim, hidden_dim, latent_dim, dropout_rate=0.1):\n        super(ProteinVAE, self).__init__()\n        \n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.latent_dim = latent_dim\n        \n        # Encoder network\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(hidden_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(dropout_rate)\n        )\n        \n        # Latent space projection\n        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n        \n        # Decoder network\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(hidden_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(hidden_dim, input_dim)\n        )\n    \n    def encode(self, x):\n        \"\"\"Encode input to latent space parameters\"\"\"\n        h = self.encoder(x)\n        mu = self.fc_mu(h)\n        log_var = self.fc_var(h)\n        return mu, log_var\n    \n    def reparameterize(self, mu, log_var):\n        \"\"\"Reparameterization trick for sampling from latent distribution\"\"\"\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        z = mu + eps * std\n        return z\n    \n    def decode(self, z):\n        \"\"\"Decode from latent space to original space\"\"\"\n        return self.decoder(z)\n    \n    def forward(self, x):\n        \"\"\"Full forward pass: encode -> sample -> decode\"\"\"\n        mu, log_var = self.encode(x)\n        z = self.reparameterize(mu, log_var)\n        x_reconstructed = self.decode(z)\n        return x_reconstructed, mu, log_var\n\ndef vae_loss_function(recon_x, x, mu, log_var, beta=1.0):\n    \"\"\"\n    VAE loss function combining reconstruction loss and KL divergence\n    \n    Args:\n        recon_x: Reconstructed input\n        x: Original input\n        mu: Mean of the latent distribution\n        log_var: Log variance of the latent distribution\n        beta: Weight of the KL divergence term\n    \"\"\"\n    # Binary cross entropy for reconstruction\n    BCE = F.binary_cross_entropy_with_logits(recon_x, x, reduction='sum')\n    \n    # KL divergence\n    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n    \n    return BCE + beta * KLD","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.005502Z","iopub.execute_input":"2025-02-27T21:43:04.005690Z","iopub.status.idle":"2025-02-27T21:43:04.028907Z","shell.execute_reply.started":"2025-02-27T21:43:04.005673Z","shell.execute_reply":"2025-02-27T21:43:04.028246Z"}},"outputs":[],"execution_count":261},{"cell_type":"code","source":"class DiffusionTrainer:\n    def __init__(self, model, device, n_timesteps=1000, beta_start=1e-4, beta_end=0.02, noise_schedule='cosine'):\n        \"\"\"\n        Diffusion model training controller\n        \n        Args:\n            model: DiffusionModel\n            device: Torch device\n            n_timesteps: Number of diffusion steps\n            beta_start, beta_end: Noise schedule parameters (for linear schedule)\n            noise_schedule: 'linear' or 'cosine'\n        \"\"\"\n        self.model = model\n        self.device = device\n        self.n_timesteps = n_timesteps\n        self.noise_schedule = noise_schedule\n        \n        if noise_schedule == 'linear':\n            # Linear noise schedule\n            self.betas = torch.linspace(beta_start, beta_end, n_timesteps).to(device)\n            self.alphas = 1. - self.betas\n            self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n            self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n            self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n            \n            # Calculations for diffusion q(x_t | x_{t-1})\n            self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n            self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n            \n            # Calculations for posterior q(x_{t-1} | x_t, x_0)\n            self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n        elif noise_schedule == 'cosine':\n            # Cosine noise schedule\n            cosine_scheduler = CosineBetaScheduler(n_timesteps)\n            self.betas = cosine_scheduler.get_betas().to(device)\n            self.alphas = 1. - self.betas\n            self.alphas_cumprod = cosine_scheduler.get_alphas_cumprod().to(device)\n            self.alphas_cumprod_prev = cosine_scheduler.get_alphas_cumprod_prev().to(device)\n            self.sqrt_recip_alphas = cosine_scheduler.get_sqrt_recip_alphas().to(device)\n            self.sqrt_alphas_cumprod = cosine_scheduler.get_sqrt_alphas_cumprod().to(device)\n            self.sqrt_one_minus_alphas_cumprod = cosine_scheduler.get_sqrt_one_minus_alphas_cumprod().to(device)\n            self.posterior_variance = cosine_scheduler.get_posterior_variance().to(device)\n        else:\n            raise ValueError(f\"Invalid noise schedule: {noise_schedule}\")\n    \n    def q_sample(self, x_start, t, noise=None):\n        \"\"\"Forward diffusion process: add noise to data\"\"\"\n        if noise is None:\n            noise = torch.randn_like(x_start)\n            \n        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].reshape(-1, 1)\n        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)\n        \n        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n    \n    def p_losses(self, x_start, t, noise=None):\n        \"\"\"Calculate loss for denoising diffusion\"\"\"\n        if noise is None:\n            noise = torch.randn_like(x_start)\n            \n        x_noisy = self.q_sample(x_start, t, noise)\n        predicted_noise = self.model(x_noisy, t.reshape(-1, 1).float() / self.n_timesteps)\n        \n        loss = F.mse_loss(predicted_noise, noise)\n        return loss\n    \n    @torch.no_grad()\n    def p_sample(self, x, t):\n        \"\"\"Sample from the model at timestep t\"\"\"\n        betas_t = self.betas[t].reshape(-1, 1)\n        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)\n        sqrt_recip_alphas_t = self.sqrt_recip_alphas[t].reshape(-1, 1)\n        \n        # Use our model (noise predictor) to predict the mean\n        model_mean = sqrt_recip_alphas_t * (\n            x - betas_t * self.model(x, t.reshape(-1, 1).float() / self.n_timesteps) / sqrt_one_minus_alphas_cumprod_t\n        )\n        \n        # Handle the case where t contains a mix of 0 and non-zero values\n        if (t == 0).any():\n            return model_mean\n        else:\n            posterior_variance_t = self.posterior_variance[t].reshape(-1, 1)\n            noise = torch.randn_like(x)\n            # Algorithm 2 line 4:\n            return model_mean + torch.sqrt(posterior_variance_t) * noise\n    \n    @torch.no_grad()\n    def p_sample_loop(self, shape):\n        \"\"\"Generate samples by sampling backwards through the diffusion process\"\"\"\n        self.model.eval()\n        device = next(self.model.parameters()).device\n        \n        b = shape[0]\n        # Start from pure noise\n        img = torch.randn(shape).to(device)\n        imgs = []\n        \n        for i in tqdm(reversed(range(0, self.n_timesteps)), desc='Sampling', total=self.n_timesteps):\n            t = torch.full((b,), i, device=device, dtype=torch.long)\n            img = self.p_sample(img, t)\n            imgs.append(img.cpu().numpy())\n        \n        return img, imgs\n    \n    def sample(self, n_samples, shape):\n        \"\"\"Generate new protein samples using the diffusion model\"\"\"\n        sample_shape = (n_samples, shape)\n        samples, diffusion_steps = self.p_sample_loop(sample_shape)\n        \n        # Apply sigmoid to map values to 0-1 range\n        samples = torch.sigmoid(samples)\n        \n        return samples, diffusion_steps\n\nclass DiffusionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, time_embed_dim=128, dropout_rate=0.1):\n        super(DiffusionModel, self).__init__()\n        \n        self.input_dim = input_dim\n        self.time_embed_dim = time_embed_dim\n        \n        # Time embedding\n        self.time_embed = nn.Sequential(\n            nn.Linear(1, time_embed_dim),\n            nn.SiLU(),\n            nn.Linear(time_embed_dim, time_embed_dim),\n        )\n        \n        # Main network\n        self.net = nn.Sequential(\n            nn.Linear(input_dim + time_embed_dim, hidden_dim),  # Fix: input_dim + time_embed_dim\n            nn.BatchNorm1d(hidden_dim),\n            nn.SiLU(),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(hidden_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.SiLU(),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(hidden_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.SiLU(),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(hidden_dim, input_dim)\n        )\n    \n    def forward(self, x, t):\n        \"\"\"\n        Forward pass\n        \n        Args:\n            x: Input data [batch_size, input_dim]\n            t: Timesteps [batch_size, 1]\n        \"\"\"\n        t_emb = self.time_embed(t)  # Shape: (batch_size, time_embed_dim)\n        x_input = torch.cat([x, t_emb], dim=1)  # Concatenate x and time embedding\n        return self.net(x_input)\n\nclass DiffusionTrainer:\n    def __init__(self, model, device, n_timesteps=1000, beta_start=1e-4, beta_end=0.02):\n        \"\"\"\n        Diffusion model training controller\n        \n        Args:\n            model: DiffusionModel\n            device: Torch device\n            n_timesteps: Number of diffusion steps\n            beta_start, beta_end: Noise schedule parameters\n        \"\"\"\n        self.model = model\n        self.device = device\n        self.n_timesteps = n_timesteps\n        \n        # Linear noise schedule\n        self.betas = torch.linspace(beta_start, beta_end, n_timesteps).to(device)\n        self.alphas = 1. - self.betas\n        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n        \n        # Calculations for diffusion q(x_t | x_{t-1})\n        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n        \n        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n    \n    def q_sample(self, x_start, t, noise=None):\n        \"\"\"Forward diffusion process: add noise to data\"\"\"\n        if noise is None:\n            noise = torch.randn_like(x_start)\n            \n        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].reshape(-1, 1)\n        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)\n        \n        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n    \n    def p_losses(self, x_start, t, noise=None):\n        \"\"\"Calculate loss for denoising diffusion\"\"\"\n        if noise is None:\n            noise = torch.randn_like(x_start)\n            \n        x_noisy = self.q_sample(x_start, t, noise)\n        predicted_noise = self.model(x_noisy, t.reshape(-1, 1).float() / self.n_timesteps)\n        \n        loss = F.mse_loss(predicted_noise, noise)\n        return loss\n    \n    @torch.no_grad()\n    def p_sample(self, x, t):\n        \"\"\"Sample from the model at timestep t\"\"\"\n        betas_t = self.betas[t].reshape(-1, 1)\n        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)\n        sqrt_recip_alphas_t = self.sqrt_recip_alphas[t].reshape(-1, 1)\n        \n        # Use our model (noise predictor) to predict the mean\n        model_mean = sqrt_recip_alphas_t * (\n            x - betas_t * self.model(x, t.reshape(-1, 1).float() / self.n_timesteps) / sqrt_one_minus_alphas_cumprod_t\n        )\n        \n        # Handle the case where t contains a mix of 0 and non-zero values\n        if (t == 0).any():\n            return model_mean\n        else:\n            posterior_variance_t = self.posterior_variance[t].reshape(-1, 1)\n            noise = torch.randn_like(x)\n            # Algorithm 2 line 4:\n            return model_mean + torch.sqrt(posterior_variance_t) * noise\n    \n    @torch.no_grad()\n    def p_sample_loop(self, shape):\n        \"\"\"Generate samples by sampling backwards through the diffusion process\"\"\"\n        self.model.eval()\n        device = next(self.model.parameters()).device\n        \n        b = shape[0]\n        # Start from pure noise\n        img = torch.randn(shape).to(device)\n        imgs = []\n        \n        for i in tqdm(reversed(range(0, self.n_timesteps)), desc='Sampling', total=self.n_timesteps):\n            t = torch.full((b,), i, device=device, dtype=torch.long)\n            img = self.p_sample(img, t)\n            imgs.append(img.cpu().numpy())\n        \n        return img, imgs\n    \n    def sample(self, n_samples, shape):\n        \"\"\"Generate new protein samples using the diffusion model\"\"\"\n        sample_shape = (n_samples, shape)\n        samples, diffusion_steps = self.p_sample_loop(sample_shape)\n        \n        # Apply sigmoid to map values to 0-1 range\n        samples = torch.sigmoid(samples)\n        \n        return samples, diffusion_steps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.030059Z","iopub.execute_input":"2025-02-27T21:43:04.030342Z","iopub.status.idle":"2025-02-27T21:43:04.055117Z","shell.execute_reply.started":"2025-02-27T21:43:04.030322Z","shell.execute_reply":"2025-02-27T21:43:04.054439Z"}},"outputs":[],"execution_count":262},{"cell_type":"code","source":"# Cell 6: Training Utilities (Updated for Stability)\ndef train_diffusion_model(diffusion_model, train_loader, val_loader, device, \n                         epochs=50, lr=1e-4, weight_decay=1e-5, use_amp=True, model_dir='models',\n                         noise_schedule='cosine'):\n    \"\"\"Train the diffusion model\"\"\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_path = os.path.join(model_dir, 'best_diffusion_model.pt')\n    \n    diffusion_trainer = DiffusionTrainer(diffusion_model, device, noise_schedule=noise_schedule)\n    \n    optimizer = torch.optim.AdamW(\n        diffusion_model.parameters(),\n        lr=lr,\n        weight_decay=weight_decay\n    )\n    \n    # Learning rate warm-up and cosine annealing\n    total_steps = len(train_loader) * epochs\n    scheduler = WarmupCosineScheduler(optimizer, warmup_steps=warmup_steps, total_steps=total_steps)\n    \n    early_stopping = EarlyStopping(patience=10, save_path=model_path)\n    scaler = GradScaler() if use_amp else None\n    \n    train_losses = []\n    val_losses = []\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        # Training phase\n        diffusion_model.train()\n        train_loss = 0\n        batch_count = 0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        for batch in progress_bar:\n            optimizer.zero_grad()\n            \n            x = batch.to(device, non_blocking=True)\n            batch_size = x.shape[0]\n            \n            # Sample random timesteps\n            t = torch.randint(0, diffusion_trainer.n_timesteps, (batch_size,), device=device).long()\n            \n            if use_amp:\n                with autocast():\n                    loss = diffusion_trainer.p_losses(x, t)\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                loss = diffusion_trainer.p_losses(x, t)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item()\n            batch_count += 1\n            \n            progress_bar.set_postfix({'loss': loss.item()})\n            \n            # Free up memory\n            del x, t, loss\n            \n            # Update learning rate\n            scheduler.step()\n        \n        # Validation phase\n        diffusion_model.eval()\n        val_loss = 0\n        val_batches = 0\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                x = batch.to(device, non_blocking=True)\n                batch_size = x.shape[0]\n                \n                # Sample random timesteps\n                t = torch.randint(0, diffusion_trainer.n_timesteps, (batch_size,), device=device).long()\n                \n                if use_amp:\n                    with autocast():\n                        loss = diffusion_trainer.p_losses(x, t)\n                else:\n                    loss = diffusion_trainer.p_losses(x, t)\n                \n                val_loss += loss.item()\n                val_batches += 1\n                \n                del x, t, loss\n        \n        avg_val_loss = val_loss / val_batches\n        val_losses.append(avg_val_loss)\n        \n        # Check early stopping and save best model\n        early_stopping(avg_val_loss, diffusion_model)\n        if early_stopping.early_stop:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n        \n        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n        \n        # Memory cleanup\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    end_time = time.time()\n    training_time = end_time - start_time\n    print(f\"Diffusion model training completed in {training_time:.2f} seconds\")\n    \n    # Load best model if it exists, otherwise save the current model\n    if os.path.exists(model_path):\n        diffusion_model.load_state_dict(torch.load(model_path))\n    else:\n        torch.save(diffusion_model.state_dict(), model_path)\n        print(f\"Saved final model as best model to {model_path}\")\n    \n    # Save training history\n    history = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'training_time': training_time,\n        'epochs': len(train_losses)\n    }\n    \n    with open(os.path.join(model_dir, 'diffusion_training_history.json'), 'w') as f:\n        json.dump(history, f)\n    \n    return diffusion_model, diffusion_trainer, train_losses, val_losses\n\nclass EarlyStopping:\n    def __init__(self, patience=7, min_delta=0, save_path='best_model.pt'):\n        \"\"\"\n        Early stopping controller\n        \n        Args:\n            patience: How many epochs to wait for improvement\n            min_delta: Minimum change to qualify as improvement\n            save_path: Where to save the best model\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n        self.save_path = save_path\n    \n    def __call__(self, val_loss, model):\n        \"\"\"Check if training should stop and save model if it's the best so far\"\"\"\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(model)\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            print(f\"Early stopping counter: {self.counter}/{self.patience}\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.save_checkpoint(model)\n            self.counter = 0\n    \n    def save_checkpoint(self, model):\n        \"\"\"Save model checkpoint\"\"\"\n        torch.save(model.state_dict(), self.save_path)\n        print(f'Model saved to {self.save_path}')\n\ndef train_model(model, train_loader, val_loader, device, epochs=100, lr=1e-3,\n               beta=1.0, weight_decay=1e-5, use_amp=True, model_dir='models'):\n    \"\"\"\n    Train the VAE model\n    \n    Args:\n        model: VAE model\n        train_loader, val_loader: Data loaders\n        device: Torch device\n        epochs: Number of epochs\n        lr: Learning rate\n        beta: Weight of KL divergence in loss function\n        weight_decay: L2 regularization\n        use_amp: Whether to use automatic mixed precision\n        model_dir: Directory to save models\n    \"\"\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_path = os.path.join(model_dir, 'best_vae_model.pt')\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=lr,\n        weight_decay=weight_decay\n    )\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=epochs, eta_min=lr/10\n    )\n    \n    early_stopping = EarlyStopping(patience=10, save_path=model_path)\n    scaler = GradScaler() if use_amp else None\n    \n    train_losses = []\n    val_losses = []\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        train_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        \n        for batch_idx, data in enumerate(progress_bar):\n            data = data.to(device, non_blocking=True)\n            optimizer.zero_grad()\n            \n            if use_amp:\n                # Fix: Remove device_type parameter\n                with autocast():\n                    recon_batch, mu, log_var = model(data)\n                    loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                recon_batch, mu, log_var = model(data)\n                loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item()\n            progress_bar.set_postfix({'loss': loss.item()})\n            \n            # Clean up memory\n            del data, recon_batch, mu, log_var, loss\n        \n        scheduler.step()\n        \n        # Calculate average training loss\n        avg_train_loss = train_loss / len(train_loader.dataset)\n        train_losses.append(avg_train_loss)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0\n        \n        with torch.no_grad():\n            for data in val_loader:\n                data = data.to(device, non_blocking=True)\n                \n                if use_amp:\n                    # Fix: Remove device_type parameter\n                    with autocast():\n                        recon_batch, mu, log_var = model(data)\n                        loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                else:\n                    recon_batch, mu, log_var = model(data)\n                    loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                \n                val_loss += loss.item()\n                \n                # Clean up memory\n                del data, recon_batch, mu, log_var, loss\n        \n        # Calculate average validation loss\n        avg_val_loss = val_loss / len(val_loader.dataset)\n        val_losses.append(avg_val_loss)\n        \n        # Check early stopping\n        early_stopping(avg_val_loss, model)\n        if early_stopping.early_stop:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n        \n        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n        \n        # Clean memory\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    end_time = time.time()\n    training_time = end_time - start_time\n    print(f\"Training completed in {training_time:.2f} seconds\")\n    \n    # Load best model\n    model.load_state_dict(torch.load(model_path))\n    \n    # Save training history\n    history = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'training_time': training_time,\n        'epochs': len(train_losses)\n    }\n    \n    with open(os.path.join(model_dir, 'vae_training_history.json'), 'w') as f:\n        json.dump(history, f)\n    \n    return model, train_losses, val_losses\n        \n        \ndef train_diffusion_model(diffusion_model, train_loader, val_loader, device, \n                         epochs=50, lr=1e-4, weight_decay=1e-5, use_amp=True, model_dir='models'):\n    \"\"\"Train the diffusion model\"\"\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_path = os.path.join(model_dir, 'best_diffusion_model.pt')\n    \n    diffusion_trainer = DiffusionTrainer(diffusion_model, device)\n    \n    optimizer = torch.optim.AdamW(\n        diffusion_model.parameters(),\n        lr=lr,\n        weight_decay=weight_decay\n    )\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=epochs, eta_min=lr/10\n    )\n    \n    early_stopping = EarlyStopping(patience=10, save_path=model_path)\n    scaler = GradScaler() if use_amp else None\n    \n    train_losses = []\n    val_losses = []\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        # Training phase\n        diffusion_model.train()\n        train_loss = 0\n        batch_count = 0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        for batch in progress_bar:\n            optimizer.zero_grad()\n            \n            x = batch.to(device, non_blocking=True)\n            batch_size = x.shape[0]\n            \n            # Sample random timesteps\n            t = torch.randint(0, diffusion_trainer.n_timesteps, (batch_size,), device=device).long()\n            \n            if use_amp:\n                with autocast():\n                    loss = diffusion_trainer.p_losses(x, t)\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                loss = diffusion_trainer.p_losses(x, t)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item()\n            batch_count += 1\n            \n            progress_bar.set_postfix({'loss': loss.item()})\n            \n            # Free up memory\n            del x, t, loss\n        \n        if scheduler is not None:\n            scheduler.step()\n        \n        avg_train_loss = train_loss / batch_count\n        train_losses.append(avg_train_loss)\n        \n        # Validation phase\n        diffusion_model.eval()\n        val_loss = 0\n        val_batches = 0\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                x = batch.to(device, non_blocking=True)\n                batch_size = x.shape[0]\n                \n                # Sample random timesteps\n                t = torch.randint(0, diffusion_trainer.n_timesteps, (batch_size,), device=device).long()\n                \n                if use_amp:\n                    with autocast():\n                        loss = diffusion_trainer.p_losses(x, t)\n                else:\n                    loss = diffusion_trainer.p_losses(x, t)\n                \n                val_loss += loss.item()\n                val_batches += 1\n                \n                del x, t, loss\n        \n        avg_val_loss = val_loss / val_batches\n        val_losses.append(avg_val_loss)\n        \n        # Check early stopping and save best model\n        early_stopping(avg_val_loss, diffusion_model)\n        if early_stopping.early_stop:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n        \n        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n        \n        # Memory cleanup\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    end_time = time.time()\n    training_time = end_time - start_time\n    print(f\"Diffusion model training completed in {training_time:.2f} seconds\")\n    \n    # Load best model if it exists, otherwise save the current model\n    if os.path.exists(model_path):\n        diffusion_model.load_state_dict(torch.load(model_path))\n    else:\n        torch.save(diffusion_model.state_dict(), model_path)\n        print(f\"Saved final model as best model to {model_path}\")\n    \n    # Save training history\n    history = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'training_time': training_time,\n        'epochs': len(train_losses)\n    }\n    \n    with open(os.path.join(model_dir, 'diffusion_training_history.json'), 'w') as f:\n        json.dump(history, f)\n    \n    return diffusion_model, diffusion_trainer, train_losses, val_losses         ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.069986Z","iopub.execute_input":"2025-02-27T21:43:04.070305Z","iopub.status.idle":"2025-02-27T21:43:04.101394Z","shell.execute_reply.started":"2025-02-27T21:43:04.070273Z","shell.execute_reply":"2025-02-27T21:43:04.100604Z"}},"outputs":[],"execution_count":263},{"cell_type":"code","source":"# Cell 6: Training Utilities (Fixed)\ndef train_model(model, train_loader, val_loader, device, epochs=100, lr=1e-3,\n               beta=1.0, weight_decay=1e-5, use_amp=True, model_dir='models'):\n    \"\"\"\n    Train the VAE model\n    \n    Args:\n        model: VAE model\n        train_loader, val_loader: Data loaders\n        device: Torch device\n        epochs: Number of epochs\n        lr: Learning rate\n        beta: Weight of KL divergence in loss function\n        weight_decay: L2 regularization\n        use_amp: Whether to use automatic mixed precision\n        model_dir: Directory to save models\n    \"\"\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_path = os.path.join(model_dir, 'best_vae_model.pt')\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=lr,\n        weight_decay=weight_decay\n    )\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=epochs, eta_min=lr/10\n    )\n    \n    early_stopping = EarlyStopping(patience=10, save_path=model_path)\n    scaler = GradScaler() if use_amp else None\n    \n    train_losses = []\n    val_losses = []\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        train_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        \n        for batch_idx, data in enumerate(progress_bar):\n            data = data.to(device, non_blocking=True)\n            optimizer.zero_grad()\n            \n            if use_amp:\n                with autocast():\n                    recon_batch, mu, log_var = model(data)\n                    loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                recon_batch, mu, log_var = model(data)\n                loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item()\n            progress_bar.set_postfix({'loss': loss.item()})\n            \n            # Clean up memory\n            del data, recon_batch, mu, log_var, loss\n        \n        scheduler.step()\n        \n        # Calculate average training loss\n        avg_train_loss = train_loss / len(train_loader.dataset)\n        train_losses.append(avg_train_loss)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0\n        \n        with torch.no_grad():\n            for data in val_loader:\n                data = data.to(device, non_blocking=True)\n                \n                if use_amp:\n                    with autocast():\n                        recon_batch, mu, log_var = model(data)\n                        loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                else:\n                    recon_batch, mu, log_var = model(data)\n                    loss = vae_loss_function(recon_batch, data, mu, log_var, beta=beta)\n                \n                val_loss += loss.item()\n                \n                # Clean up memory\n                del data, recon_batch, mu, log_var, loss\n        \n        # Calculate average validation loss\n        avg_val_loss = val_loss / len(val_loader.dataset)\n        val_losses.append(avg_val_loss)\n        \n        # Check early stopping\n        early_stopping(avg_val_loss, model)\n        if early_stopping.early_stop:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n        \n        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n        \n        # Clean memory\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    end_time = time.time()\n    training_time = end_time - start_time\n    print(f\"Training completed in {training_time:.2f} seconds\")\n    \n    # Load best model\n    model.load_state_dict(torch.load(model_path))\n    \n    # Save training history\n    history = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'training_time': training_time,\n        'epochs': len(train_losses)\n    }\n    \n    with open(os.path.join(model_dir, 'vae_training_history.json'), 'w') as f:\n        json.dump(history, f)\n    \n    return model, train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.102417Z","iopub.execute_input":"2025-02-27T21:43:04.102683Z","iopub.status.idle":"2025-02-27T21:43:04.127898Z","shell.execute_reply.started":"2025-02-27T21:43:04.102652Z","shell.execute_reply":"2025-02-27T21:43:04.127009Z"}},"outputs":[],"execution_count":264},{"cell_type":"code","source":"# Cell 7: Evaluation and Visualization Functions (Fixed for Kaggle)\n@torch.no_grad()\ndef evaluate_model(model, test_loader, device, use_amp=True):\n    \"\"\"\n    Evaluate the VAE model on test data\n    \n    Args:\n        model: VAE model\n        test_loader: Test data loader\n        device: Torch device\n        use_amp: Whether to use automatic mixed precision\n    \"\"\"\n    model.eval()\n    test_loss = 0\n    reconstruction_error = 0\n    kl_divergence = 0\n    all_mu = []\n    all_log_var = []\n    \n    with torch.no_grad():\n        for data in tqdm(test_loader, desc=\"Evaluating\"):\n            data = data.to(device, non_blocking=True)\n            \n            if use_amp:\n                # Fix: Remove device_type parameter\n                with autocast():\n                    recon_batch, mu, log_var = model(data)\n                    loss = vae_loss_function(recon_batch, data, mu, log_var)\n            else:\n                recon_batch, mu, log_var = model(data)\n                loss = vae_loss_function(recon_batch, data, mu, log_var)\n            \n            test_loss += loss.item()\n            \n            # Component-wise losses\n            recon_error = F.binary_cross_entropy_with_logits(recon_batch, data, reduction='sum').item()\n            reconstruction_error += recon_error\n            \n            kld = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()).item()\n            kl_divergence += kld\n            \n            # Save latent space statistics\n            all_mu.append(mu.cpu().numpy())\n            all_log_var.append(log_var.cpu().numpy())\n            \n            # Clean memory\n            del data, recon_batch, mu, log_var\n    \n    # Calculate average metrics\n    test_loss /= len(test_loader.dataset)\n    reconstruction_error /= len(test_loader.dataset)\n    kl_divergence /= len(test_loader.dataset)\n    \n    # Combine all latent variables\n    all_mu = np.concatenate(all_mu, axis=0)\n    all_log_var = np.concatenate(all_log_var, axis=0)\n    \n    # Calculate statistics on latent space\n    mu_mean = np.mean(all_mu, axis=0)\n    mu_std = np.std(all_mu, axis=0)\n    var_mean = np.mean(np.exp(all_log_var), axis=0)\n    \n    # Package metrics\n    metrics = {\n        'test_loss': test_loss,\n        'reconstruction_error': reconstruction_error,\n        'kl_divergence': kl_divergence,\n        'mu_mean': mu_mean.tolist(),\n        'mu_std': mu_std.tolist(),\n        'var_mean': var_mean.tolist()\n    }\n    \n    # Clean memory\n    torch.cuda.empty_cache()\n    \n    return metrics, all_mu, all_log_var","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.129630Z","iopub.execute_input":"2025-02-27T21:43:04.129868Z","iopub.status.idle":"2025-02-27T21:43:04.156518Z","shell.execute_reply.started":"2025-02-27T21:43:04.129849Z","shell.execute_reply":"2025-02-27T21:43:04.155908Z"}},"outputs":[],"execution_count":265},{"cell_type":"code","source":"# Cell 8: Protein Generation and Analysis\nclass ProteinGenerator:\n    def __init__(self, vae_model, diffusion_trainer, device):\n        \"\"\"\n        Protein structure generator using both VAE and diffusion models\n        \n        Args:\n            vae_model: Trained VAE model\n            diffusion_trainer: Trained diffusion model trainer\n            device: Torch device\n        \"\"\"\n        self.vae_model = vae_model\n        self.diffusion_trainer = diffusion_trainer\n        self.device = device\n        \n    def generate_from_vae(self, num_samples=10, temperature=1.0):\n        \"\"\"Generate protein structures using the VAE model\"\"\"\n        self.vae_model.eval()\n        \n        with torch.no_grad():\n            # Sample from latent space\n            z = torch.randn(num_samples, self.vae_model.latent_dim).to(self.device) * temperature\n            \n            # Decode\n            samples = self.vae_model.decode(z)\n            samples = torch.sigmoid(samples)\n            \n        return samples.cpu().numpy()\n    \n    def generate_from_diffusion(self, num_samples=10):\n        \"\"\"Generate protein structures using the diffusion model\"\"\"\n        samples, _ = self.diffusion_trainer.sample(n_samples=num_samples, shape=self.vae_model.input_dim)\n        return samples.cpu().numpy()\n    \n    def interpolate_structures(self, structure1, structure2, num_steps=10):\n        \"\"\"Interpolate between two protein structures in latent space\"\"\"\n        self.vae_model.eval()\n        \n        with torch.no_grad():\n            # Convert to tensors\n            s1 = torch.tensor(structure1, dtype=torch.float32).unsqueeze(0).to(self.device)\n            s2 = torch.tensor(structure2, dtype=torch.float32).unsqueeze(0).to(self.device)\n            \n            # Encode to latent space\n            mu1, _ = self.vae_model.encode(s1)\n            mu2, _ = self.vae_model.encode(s2)\n            \n            # Interpolate in latent space\n            alphas = np.linspace(0, 1, num_steps)\n            interpolations = []\n            \n            for alpha in alphas:\n                mu_interp = alpha * mu1 + (1 - alpha) * mu2\n                decoded = torch.sigmoid(self.vae_model.decode(mu_interp))\n                interpolations.append(decoded.cpu().numpy()[0])\n        \n        return interpolations\n    \n    def analyze_structure(self, structure):\n        \"\"\"Analyze a protein structure\"\"\"\n        # Calculate basic statistics\n        mean = np.mean(structure)\n        std = np.std(structure)\n        min_val = np.min(structure)\n        max_val = np.max(structure)\n        \n        # Find peaks (potential binding sites or structural motifs)\n        from scipy.signal import find_peaks\n        peaks, _ = find_peaks(structure, height=0.5, distance=10)\n        \n        # Calculate periodicity using autocorrelation\n        from scipy.signal import correlate\n        autocorr = correlate(structure, structure, mode='full')\n        autocorr = autocorr[len(autocorr)//2:]\n        \n        # Package results\n        analysis = {\n            'mean': float(mean),\n            'std': float(std),\n            'min': float(min_val),\n            'max': float(max_val),\n            'num_peaks': len(peaks),\n            'peak_positions': peaks.tolist(),\n            'autocorrelation': autocorr[:100].tolist()  # First 100 points\n        }\n        \n        return analysis\n\ndef generate_protein_report(generator, num_samples=10, output_dir='protein_report'):\n    \"\"\"Generate a comprehensive report on protein structures\"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Generate samples\n    print(\"Generating samples from VAE...\")\n    vae_samples = generator.generate_from_vae(num_samples)\n    \n    print(\"Generating samples from diffusion model...\")\n    diffusion_samples = generator.generate_from_diffusion(num_samples)\n    \n    # Analyze samples\n    print(\"Analyzing generated structures...\")\n    vae_analyses = [generator.analyze_structure(s) for s in vae_samples]\n    diffusion_analyses = [generator.analyze_structure(s) for s in diffusion_samples]\n    \n    # Create interpolations\n    print(\"Creating interpolations...\")\n    interpolations = generator.interpolate_structures(vae_samples[0], vae_samples[1])\n    \n    # Plot samples\n    plt.figure(figsize=(15, 10))\n\n    # Plot samples\n    plt.figure(figsize=(15, 10))\n    \n    # VAE samples\n    for i in range(min(5, num_samples)):\n        plt.subplot(3, 5, i+1)\n        plt.plot(vae_samples[i])\n        plt.title(f'VAE Sample {i+1}')\n        plt.ylim(0, 1)\n        plt.axis('off')\n    \n    # Diffusion samples\n    for i in range(min(5, num_samples)):\n        plt.subplot(3, 5, i+6)\n        plt.plot(diffusion_samples[i])\n        plt.title(f'Diffusion Sample {i+1}')\n        plt.ylim(0, 1)\n        plt.axis('off')\n    \n    # Interpolations\n    for i in range(min(5, len(interpolations))):\n        plt.subplot(3, 5, i+11)\n        plt.plot(interpolations[i])\n        plt.title(f'Interpolation {i+1}')\n        plt.ylim(0, 1)\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'protein_samples.png'))\n    plt.close()\n    \n    # Plot statistics\n    plt.figure(figsize=(15, 10))\n    \n    # Mean values\n    vae_means = [a['mean'] for a in vae_analyses]\n    diff_means = [a['mean'] for a in diffusion_analyses]\n    \n    plt.subplot(2, 2, 1)\n    plt.boxplot([vae_means, diff_means], labels=['VAE', 'Diffusion'])\n    plt.title('Mean Values')\n    \n    # Standard deviations\n    vae_stds = [a['std'] for a in vae_analyses]\n    diff_stds = [a['std'] for a in diffusion_analyses]\n    \n    plt.subplot(2, 2, 2)\n    plt.boxplot([vae_stds, diff_stds], labels=['VAE', 'Diffusion'])\n    plt.title('Standard Deviations')\n    \n    # Number of peaks\n    vae_peaks = [a['num_peaks'] for a in vae_analyses]\n    diff_peaks = [a['num_peaks'] for a in diffusion_analyses]\n    \n    plt.subplot(2, 2, 3)\n    plt.boxplot([vae_peaks, diff_peaks], labels=['VAE', 'Diffusion'])\n    plt.title('Number of Peaks')\n    \n    # Autocorrelation\n    plt.subplot(2, 2, 4)\n    plt.plot(vae_analyses[0]['autocorrelation'], label='VAE')\n    plt.plot(diffusion_analyses[0]['autocorrelation'], label='Diffusion')\n    plt.title('Autocorrelation (Sample 1)')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'protein_statistics.png'))\n    plt.close()\n    \n    # Save analyses to JSON\n    analyses = {\n        'vae_samples': vae_analyses,\n        'diffusion_samples': diffusion_analyses,\n        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    }\n    \n    with open(os.path.join(output_dir, 'protein_analyses.json'), 'w') as f:\n        json.dump(analyses, f, indent=4)\n    \n    print(f\"Protein report generated in {output_dir}\")\n    return analyses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.157402Z","iopub.execute_input":"2025-02-27T21:43:04.157604Z","iopub.status.idle":"2025-02-27T21:43:04.180020Z","shell.execute_reply.started":"2025-02-27T21:43:04.157586Z","shell.execute_reply":"2025-02-27T21:43:04.179247Z"}},"outputs":[],"execution_count":266},{"cell_type":"code","source":"# Cell 9: Complete Pipeline (Updated for Stability)\ndef run_helixsynth_pipeline(input_dim=400, hidden_dim=256, latent_dim=32, \n                           batch_size=128, vae_epochs=50, diffusion_epochs=30,\n                           use_synthetic_data=True, num_samples=1000,\n                           output_dir='helixsynth_output',):\n    \"\"\"\n    Run the complete HelixSynth-Pro pipeline\n    \n    Args:\n        input_dim: Dimension of protein structure vectors\n        hidden_dim: Hidden dimension for models\n        latent_dim: Latent dimension for VAE\n        batch_size: Batch size for training\n        vae_epochs: Number of epochs for VAE training\n        diffusion_epochs: Number of epochs for diffusion model training\n        use_synthetic_data: Whether to use synthetic data\n        num_samples: Number of samples if using synthetic data\n        output_dir: Directory for all outputs\n        noise_schedule: 'linear' or 'cosine'\n        warmup_steps: Number of warm-up steps for learning rate\n    \"\"\"\n    # Create output directories\n    os.makedirs(output_dir, exist_ok=True)\n    model_dir = os.path.join(output_dir, 'models')\n    data_dir = os.path.join(output_dir, 'data')\n    vis_dir = os.path.join(output_dir, 'visualizations')\n    report_dir = os.path.join(output_dir, 'protein_report')\n    \n    os.makedirs(model_dir, exist_ok=True)\n    os.makedirs(data_dir, exist_ok=True)\n    os.makedirs(vis_dir, exist_ok=True)\n    os.makedirs(report_dir, exist_ok=True)\n    \n    # Set up device and seed\n    device = setup_gpu()\n    seed = set_seed(42)\n    \n    # Create or load data\n    if use_synthetic_data:\n        print(\"Creating synthetic dataset...\")\n        train_dir = os.path.join(data_dir, 'train')\n        val_dir = os.path.join(data_dir, 'val')\n        test_dir = os.path.join(data_dir, 'test')\n        \n        os.makedirs(train_dir, exist_ok=True)\n        os.makedirs(val_dir, exist_ok=True)\n        os.makedirs(test_dir, exist_ok=True)\n        \n        # Create datasets with different sizes\n        create_synthetic_dataset(train_dir, int(num_samples * 0.7), input_dim, structured=True)\n        create_synthetic_dataset(val_dir, int(num_samples * 0.15), input_dim, structured=True)\n        create_synthetic_dataset(test_dir, int(num_samples * 0.15), input_dim, structured=True)\n        \n        # Create data loaders\n        train_loader, val_loader, test_loader = create_data_loaders(\n            data_path=data_dir,\n            batch_size=batch_size,\n            num_workers=4\n        )\n    else:\n        # Assume data is already available\n        print(\"Loading existing dataset...\")\n        train_loader, val_loader, test_loader = create_data_loaders(\n            data_path=data_dir,\n            batch_size=batch_size,\n            num_workers=4\n        )\n    \n    # Initialize and train VAE model\n    print(\"\\n\" + \"=\"*50)\n    print(\"Initializing and training VAE model...\")\n    print(\"=\"*50)\n    \n    vae_model = ProteinVAE(input_dim, hidden_dim, latent_dim).to(device)\n    vae_model, vae_train_losses, vae_val_losses = train_model(\n        vae_model, train_loader, val_loader, device,\n        epochs=vae_epochs,\n        model_dir=model_dir\n    )\n    \n    # Plot VAE training history\n    plot_training_history(\n        vae_train_losses, vae_val_losses,\n        save_path=os.path.join(vis_dir, 'vae_training_history.png')\n    )\n    \n    # Initialize and train diffusion model\n    print(\"\\n\" + \"=\"*50)\n    print(\"Initializing and training diffusion model...\")\n    print(\"=\"*50)\n    \n    diffusion_model = DiffusionModel(input_dim, hidden_dim).to(device)\n    diffusion_model, diffusion_trainer, diff_train_losses, diff_val_losses = train_diffusion_model(\n        diffusion_model, train_loader, val_loader, device,\n        epochs=diffusion_epochs,\n        lr=1e-4,\n        weight_decay=1e-5,\n        use_amp=True,\n        model_dir=model_dir,\n    )\n    \n    # Plot diffusion training history\n    plot_training_history(\n        diff_train_losses, diff_val_losses,\n        save_path=os.path.join(vis_dir, 'diffusion_training_history.png')\n    )\n    \n    # Create visualizations\n    print(\"\\n\" + \"=\"*50)\n    print(\"Creating model visualizations...\")\n    print(\"=\"*50)\n    \n    metrics = create_visualization_pipeline(\n        vae_model, diffusion_model, diffusion_trainer,\n        test_loader, device, output_dir=vis_dir\n    )\n    \n    # Generate protein structures and report\n    print(\"\\n\" + \"=\"*50)\n    print(\"Generating protein structures and analysis report...\")\n    print(\"=\"*50)\n    \n    protein_generator = ProteinGenerator(vae_model, diffusion_trainer, device)\n    protein_analyses = generate_protein_report(\n        protein_generator, num_samples=10, output_dir=report_dir\n    )\n    \n    # Final summary\n    print(\"\\n\" + \"=\"*50)\n    print(\"HelixSynth-Pro Pipeline Complete!\")\n    print(\"=\"*50)\n    print(f\"Output directory: {output_dir}\")\n    print(f\"VAE model disentanglement score: {metrics['disentanglement_score']:.4f}\")\n    print(f\"Test reconstruction error: {metrics['reconstruction_error']:.4f}\")\n    print(f\"Generated {len(protein_analyses['vae_samples'])} protein structures with VAE\")\n    print(f\"Generated {len(protein_analyses['diffusion_samples'])} protein structures with diffusion model\")\n    \n    return {\n        'vae_model': vae_model,\n        'diffusion_model': diffusion_model,\n        'diffusion_trainer': diffusion_trainer,\n        'metrics': metrics,\n        'protein_analyses': protein_analyses\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.180752Z","iopub.execute_input":"2025-02-27T21:43:04.180934Z","iopub.status.idle":"2025-02-27T21:43:04.199736Z","shell.execute_reply.started":"2025-02-27T21:43:04.180918Z","shell.execute_reply":"2025-02-27T21:43:04.199181Z"}},"outputs":[],"execution_count":267},{"cell_type":"code","source":"# Cell 10: Execute Pipeline (Fixed for Kaggle)\nif __name__ == \"__main__\":\n    # Run the complete pipeline with Kaggle working directory\n    results = run_helixsynth_pipeline(\n        input_dim=400,\n        hidden_dim=256,\n        latent_dim=32,\n        batch_size=128,\n        vae_epochs=30,  # Reduced for faster execution\n        diffusion_epochs=20,  # Reduced for faster execution\n        use_synthetic_data=True,\n        num_samples=1000,\n        output_dir='/kaggle/working/'\n    )\n    \n    # Access models and results\n    vae_model = results['vae_model']\n    diffusion_model = results['diffusion_model']\n    diffusion_trainer = results['diffusion_trainer']\n    metrics = results['metrics']\n    protein_analyses = results['protein_analyses']\n    \n    print(\"\\nPipeline execution complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T21:43:04.200384Z","iopub.execute_input":"2025-02-27T21:43:04.200558Z","iopub.status.idle":"2025-02-27T21:44:06.657431Z","shell.execute_reply.started":"2025-02-27T21:43:04.200542Z","shell.execute_reply":"2025-02-27T21:44:06.656504Z"}},"outputs":[{"name":"stdout","text":"GPU available: Tesla T4\nNumber of GPUs: 2\nUsing 2 GPUs\nCreating synthetic dataset...\nCreated 700 synthetic protein structures in /kaggle/working/data/train\nCreated 150 synthetic protein structures in /kaggle/working/data/val\nCreated 150 synthetic protein structures in /kaggle/working/data/test\n\n==================================================\nInitializing and training VAE model...\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebfa95177f3c44759dc4330a798e2b84"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 1: Train Loss: 291.7133, Val Loss: 277.8942\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c983cc12aa443349cb2f0762f69de56"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 2: Train Loss: 286.6837, Val Loss: 276.8793\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb9ea3da6d494ddeabd7cddca5874ef2"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 3: Train Loss: 281.6980, Val Loss: 276.6276\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689bfbd6901546a69eadf3d8b0a56d6b"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 4: Train Loss: 280.0773, Val Loss: 276.7183\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5249a39e72ff4f1cae328a6e2c940671"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 5: Train Loss: 279.0123, Val Loss: 276.7144\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae2fce84c43f4b5381750b74cca21537"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 6: Train Loss: 278.2756, Val Loss: 276.5335\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a0b4814e47b4f0ebfb76f3fce7817e6"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 7: Train Loss: 277.8536, Val Loss: 276.8303\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8386af88339f4fd5ad08180d8609ab1b"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 8: Train Loss: 277.6387, Val Loss: 276.6562\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26ed05350d5a4110a0463c94d7b327a2"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 3/10\nEpoch 9: Train Loss: 277.3181, Val Loss: 276.5867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002883c0f5a0479081b3e28c293c04e9"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 4/10\nEpoch 10: Train Loss: 277.1060, Val Loss: 276.5581\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c82cf55d4b4d43b3b715cfbc1d4dc3f1"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 11: Train Loss: 277.0846, Val Loss: 276.4594\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce4b38157ef41838c86a4a1ba7491d6"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 12: Train Loss: 276.9917, Val Loss: 276.2312\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a208af59a345d5a5c8bf210f5d6ae1"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 13: Train Loss: 276.6321, Val Loss: 276.2312\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b9a3fc1f73c41c49d54b830027a92d2"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 14: Train Loss: 276.5589, Val Loss: 276.3135\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcf81745844e4f09931d17134a1704fb"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 15: Train Loss: 276.6099, Val Loss: 276.0627\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1def4369abb54c1f96e1ace54b8a8818"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 16: Train Loss: 276.4846, Val Loss: 276.3738\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fab387d30e413a9293b5aae7bf689c"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 17: Train Loss: 276.4052, Val Loss: 276.2271\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d5b4981b74413bb2df61bc091c5be9"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 3/10\nEpoch 18: Train Loss: 276.5005, Val Loss: 276.0657\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a47dbd9caa347cfa8e6bf6971ae12f5"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 19: Train Loss: 276.3143, Val Loss: 276.0068\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 20/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7551a8fc8ac450cbd76afa51a789786"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 20: Train Loss: 276.2129, Val Loss: 276.0776\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 21/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48cda3b921374edd8c1db0d1bf9c05cb"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 21: Train Loss: 276.2555, Val Loss: 275.8952\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 22/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84de882cee3840b79b81a429dccba768"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 22: Train Loss: 276.3187, Val Loss: 275.8727\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 23/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a164d0cd65944688b6af1a082733e2cc"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 23: Train Loss: 276.2204, Val Loss: 275.9176\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 24/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c759d5840df4c30b1ec836e88110f86"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 24: Train Loss: 276.1097, Val Loss: 275.9678\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 25/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2aa640575940eebc71590bc5d72f0e"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 3/10\nEpoch 25: Train Loss: 276.0657, Val Loss: 276.0407\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 26/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a0d4f4c174e47f08d5ad8f38aef807c"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_vae_model.pt\nEpoch 26: Train Loss: 276.1906, Val Loss: 275.7314\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 27/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0001db9076cc408194994e849117bc1a"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 27: Train Loss: 276.1857, Val Loss: 275.8892\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 28/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0be10915d74c28abd3e6d432f822c1"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 28: Train Loss: 276.0329, Val Loss: 275.8789\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 29/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6db599e53db4004a26817ac354a9960"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 3/10\nEpoch 29: Train Loss: 276.1090, Val Loss: 275.7903\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 30/30:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28fdbb8614943c291b272b622030190"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 4/10\nEpoch 30: Train Loss: 276.1488, Val Loss: 275.7932\nTraining completed in 49.57 seconds\n\n==================================================\nInitializing and training diffusion model...\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19ab9343936348eb81c36156942c448c"}},"metadata":{}},{"name":"stdout","text":"Model saved to /kaggle/working/models/best_diffusion_model.pt\nEpoch 1: Train Loss: 1.122412, Val Loss: 0.998214\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67c7ab79c4f54feaae8fc2c5dd190123"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 1/10\nEpoch 2: Train Loss: 1.118431, Val Loss: 1.004382\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"953b317e1f874d3aabce1fae6528f4b9"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 2/10\nEpoch 3: Train Loss: 1.111440, Val Loss: 1.016540\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9daaf15d0a84ba48bf1aaf45bf4f5ab"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 3/10\nEpoch 4: Train Loss: 1.101661, Val Loss: 0.999007\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c8e06d5cee45bd940a989efd6266b4"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 4/10\nEpoch 5: Train Loss: 1.096597, Val Loss: 1.019585\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ba9af6f17d4928919536eaa467e469"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 5/10\nEpoch 6: Train Loss: 1.086612, Val Loss: 1.028795\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b7f9b81e4a4920a8d3b73e59752a4b"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 6/10\nEpoch 7: Train Loss: 1.086777, Val Loss: 1.039493\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0e92e3062f40e48db6027a9970e380"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 7/10\nEpoch 8: Train Loss: 1.080325, Val Loss: 1.048325\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed076c545d546ef9995d2a71b5906de"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 8/10\nEpoch 9: Train Loss: 1.076284, Val Loss: 1.040262\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0884fa480d467193f4836d265b1369"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 9/10\nEpoch 10: Train Loss: 1.068329, Val Loss: 1.020258\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/20:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f39b73f109e6479a8b78e15844bcc688"}},"metadata":{}},{"name":"stdout","text":"Early stopping counter: 10/10\nEarly stopping at epoch 11\nDiffusion model training completed in 3.15 seconds\n\n==================================================\nCreating model visualizations...\n==================================================\nEvaluating VAE model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8c58b0701e4b2d9ade33c0ee059596"}},"metadata":{}},{"name":"stdout","text":"Calculating disentanglement score...\nCreating VAE visualizations...\nGenerating samples with diffusion model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sampling:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b60e4ed1c694df6ae53110a0f5338a0"}},"metadata":{}},{"name":"stdout","text":"Creating diffusion model visualizations...\nAll visualizations saved to /kaggle/working/visualizations\n\n==================================================\nGenerating protein structures and analysis report...\n==================================================\nGenerating samples from VAE...\nGenerating samples from diffusion model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sampling:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c984b66431064cf3ae84325fd5669a69"}},"metadata":{}},{"name":"stdout","text":"Analyzing generated structures...\nCreating interpolations...\nProtein report generated in /kaggle/working/protein_report\n\n==================================================\nHelixSynth-Pro Pipeline Complete!\n==================================================\nOutput directory: /kaggle/working/\nVAE model disentanglement score: 0.8485\nTest reconstruction error: 275.0474\nGenerated 10 protein structures with VAE\nGenerated 10 protein structures with diffusion model\n\nPipeline execution complete!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x1000 with 0 Axes>"},"metadata":{}}],"execution_count":268}]}